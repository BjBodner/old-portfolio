# Learning Lagrangians Of Physical Systems





<p align="center">
   <img src=https://github.com/BjBodner/Portfolio/blob/master/Machine_Learning_and_Optimization_Projects/Learning_Lagrangians_Of_Physical_Systems/All_Together.png width="300" title="Snapshot Of ATM Optimization Algorithm - in pursuit of the global minimum">
   <img src=https://github.com/BjBodner/Portfolio/blob/master/Machine_Learning_and_Optimization_Projects/Learning_Lagrangians_Of_Physical_Systems/Minibatch_Cost_Function_For_NN_Lagrangian_SHO.png width="400" title="Comparing ATM to other optimizers in the separable functions section of the BBOB testbed">
  
  
  
This project was created during my first semester at Brown, as a final project in my course on modern classical physics.

This goal of this project was to try to a representation of the lagrangians which govern behavior of a 
few physical systems, using neural networks.  The approach I took was to use multiple observations of the states of a physical system, then to use this information to learn a lagrangian which generates the observed behavior. 

## Methodology
First, I generated data over constant time intervals, using a simulation of the well-studied lagrangians, such as a 1D harmonic oscillator and a particle in a central force (like the earth around the sun). Then the derivatives of these lagrangians were taken, this process generates the equations of motion of the particles in these systems. More specifically, this allowed us to calculate the changes in the states of the particles, throughout the different time steps.  In our case these changes we the changes in the particles’ position and momenta.

## Training
Once the data was created, a complex valued neural network was trained to input current state of the system and output a single real valued number, which is exactly what the lagrangian does. 
After this step, the derivative of this function was taken, in order to predict the changes in the state
of the system (positions and momenta). The cost function used to train this system, was the 
squared difference between the predicted changes in the state of the system and the true changes which are observed in the data.
The neural networks which generate these lagrangians were trained using one of my black box optimization algorithms – the Two Mode algorithm. 
Here we can see a few of the phase-space paths which were generated by the true lagrangians, alongside the paths generated by the neural networks:

<p align="center">
   <img src=https://github.com/BjBodner/Portfolio/blob/master/Machine_Learning_and_Optimization_Projects/Learning_Lagrangians_Of_Physical_Systems/Lagrangian_NN_Results.png width="300" title="Snapshot Of ATM Optimization Algorithm - in pursuit of the global minimum">
   <img src=https://github.com/BjBodner/Portfolio/blob/master/Machine_Learning_and_Optimization_Projects/Learning_Lagrangians_Of_Physical_Systems/SHO_Lagrangian_Learning2.png width="400" title="Comparing ATM to other optimizers in the separable functions section of the BBOB testbed">
  
  
  
  




This system was able to learn very good representations of the lagrangians as can be seen in the images
of the phase space paths they generated. However, it had some difficulty dealing with 
situations that had very strong gradients and sharp state transitions, such as in the central force scenario.

